{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "473e5056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== ëŒ€ë¶„ë¥˜ ì‘ì—… ì™„ë£Œ =====\n",
      "ëŒ€ë¶„ë¥˜\n",
      "ì‹ì‚¬        1998\n",
      "ì¹´í˜/ë””ì €íŠ¸     809\n",
      "ë¹„ì™¸ì‹ì†Œë§¤      657\n",
      "ê¸°íƒ€         401\n",
      "ì£¼ì /ìœ í¥      318\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# 1. í™˜ê²½ ì„¤ì •\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 2. ë°ì´í„° ë¡œë“œ\n",
    "df_info = pd.read_csv('./data/df_info2.csv', encoding='utf-8-sig')\n",
    "df_sales = pd.read_csv('./data/df_sales2.csv', encoding='utf-8-sig')\n",
    "df_customer = pd.read_csv('./data/df_customer2.csv', encoding='utf-8-sig')\n",
    "\n",
    "# 3. ê¸°ë³¸ ì „ì²˜ë¦¬ (ì»¬ëŸ¼ ì •ë ¬ ë° ë‚ ì§œ ë³€í™˜)\n",
    "cols_order = ['ê°€ë§¹ì êµ¬ë¶„ë²ˆí˜¸', 'ê°€ë§¹ì ëª…', 'ìƒê¶Œ', 'ê°€ë§¹ì ì£¼ì†Œ', 'ê°€ë§¹ì ì£¼ì†Œ_ì„¸ë¶€', 'ì—…ì¢…', 'í”„ëœì°¨ì´ì¦ˆì—¬ë¶€', 'ê°œì„¤ì¼', 'íì—…ì¼']\n",
    "df_info = df_info[cols_order]\n",
    "df_info['ê°œì„¤ì¼'] = pd.to_datetime(df_info['ê°œì„¤ì¼'], errors='coerce')\n",
    "df_info['íì—…ì¼'] = pd.to_datetime(df_info['íì—…ì¼'], errors='coerce')\n",
    "\n",
    "# 4. ì—…ì¢… ëŒ€ë¶„ë¥˜ ì •ì˜ (Classification Rules)\n",
    "classification_rules = {\n",
    "    'ì‹ì‚¬': ['í•œì‹', 'ì¼ì‹', 'ì¤‘ì‹', 'ë¶„ì‹', 'ì¹˜í‚¨', 'í–„ë²„ê±°', 'í”¼ì', 'ìƒŒë“œìœ„ì¹˜', 'ë„ì‹œë½', 'ìŠ¤í…Œì´í¬', 'ì–‘ì‹', 'ì„¸ê³„ìš”ë¦¬', 'êµ¬ë‚´ì‹ë‹¹', 'ê¸°ì‚¬ì‹ë‹¹'],\n",
    "    'ì£¼ì /ìœ í¥': ['í˜¸í”„', 'ì£¼ì ', 'ê¼¬ì¹˜', 'ì™€ì¸', 'ë£¸ì‚´ë¡±', 'í¬ì°¨', 'ì´ìì¹´ì•¼'],\n",
    "    'ì¹´í˜/ë””ì €íŠ¸': ['ì¹´í˜', 'ë§ˆì¹´ë¡±', 'ì°¨', 'íƒ•í›„ë£¨', 'ì»¤í”¼', 'ë² ì´ì»¤ë¦¬', 'ì•„ì´ìŠ¤í¬ë¦¼', 'ë„ë„ˆì¸ ', 'ì™€í”Œ', 'ì£¼ìŠ¤'],\n",
    "    'ë¹„ì™¸ì‹ì†Œë§¤': ['ê±´ê°•', 'ê±´ì–´ë¬¼', 'ë†ì‚°ë¬¼', 'ë‹´ë°°', 'ë–¡', 'ë¯¸ê³¡', 'ë°˜ì°¬', 'ìˆ˜ì‚°', 'ì‹ë£Œ', 'ì™€ì¸ìƒµ', 'ìœ ì œí’ˆ', 'ì¸ì‚¼', 'ì£¼ë¥˜', 'ì²­ê³¼', 'ì¶•ì‚°']\n",
    "}\n",
    "\n",
    "def classify_major_category(industry, rules):\n",
    "    if not isinstance(industry, str): return 'ê¸°íƒ€'\n",
    "    for category, keywords in rules.items():\n",
    "        if any(k in industry for k in keywords):\n",
    "            return category\n",
    "    return 'ê¸°íƒ€'\n",
    "\n",
    "df_info['ëŒ€ë¶„ë¥˜'] = df_info['ì—…ì¢…'].apply(lambda x: classify_major_category(x, classification_rules))\n",
    "\n",
    "print(\"===== ëŒ€ë¶„ë¥˜ ì‘ì—… ì™„ë£Œ =====\")\n",
    "print(df_info['ëŒ€ë¶„ë¥˜'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "519421a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì™„ë£Œ =====\n"
     ]
    }
   ],
   "source": [
    "def hierarchical_imputation(df_target, df_meta, target_cols, group_keys_list):\n",
    "    \"\"\"\n",
    "    ê³„ì¸µì  ê²°ì¸¡ì¹˜ ëŒ€ì²´ í•¨ìˆ˜\n",
    "    :param df_target: ê²°ì¸¡ì¹˜ë¥¼ ì±„ìš¸ ë°ì´í„°í”„ë ˆì„ (Sales or Customer)\n",
    "    :param df_meta: ë©”íƒ€ ì •ë³´ê°€ ìˆëŠ” ë°ì´í„°í”„ë ˆì„ (Info)\n",
    "    :param target_cols: ì±„ìš¸ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸\n",
    "    :param group_keys_list: ëŒ€ì²´ ê¸°ì¤€ ê·¸ë£¹ ë¦¬ìŠ¤íŠ¸ (ìš°ì„ ìˆœìœ„ ìˆœ)\n",
    "    \"\"\"\n",
    "    # 1. ì´ìƒì¹˜ ì²˜ë¦¬ ë° ë³‘í•©\n",
    "    df_target.replace(-999999.9, np.nan, inplace=True)\n",
    "    df_merged = pd.merge(df_target, df_meta[['ê°€ë§¹ì êµ¬ë¶„ë²ˆí˜¸', 'ìƒê¶Œ', 'ì—…ì¢…', 'ëŒ€ë¶„ë¥˜']], on='ê°€ë§¹ì êµ¬ë¶„ë²ˆí˜¸', how='left')\n",
    "    \n",
    "    for col in target_cols:\n",
    "        # Level 1: ê°€ê²Œë³„(ê°€ë§¹ì êµ¬ë¶„ë²ˆí˜¸) í‰ê· /ìµœë¹ˆê°’ (ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²½ìš°)\n",
    "        if df_target is df_sales: # SalesëŠ” í‰ê· \n",
    "             df_merged[col].fillna(df_merged.groupby('ê°€ë§¹ì êµ¬ë¶„ë²ˆí˜¸')[col].transform('mean'), inplace=True)\n",
    "        else: # CustomerëŠ” ìµœë¹ˆê°’\n",
    "             df_merged[col].fillna(df_merged.groupby('ê°€ë§¹ì êµ¬ë¶„ë²ˆí˜¸')[col].transform(lambda x: x.mode()[0] if not x.mode().empty else np.nan), inplace=True)\n",
    "\n",
    "        # Level 2~N: ì§€ì •ëœ ê·¸ë£¹ í‚¤ë¡œ ìˆœì°¨ì  ëŒ€ì²´\n",
    "        for keys in group_keys_list:\n",
    "            fill_val = df_merged.groupby(keys)[col].transform(lambda x: x.mean() if df_target is df_sales else (x.mode()[0] if not x.mode().empty else np.nan))\n",
    "            df_merged[col].fillna(fill_val, inplace=True)\n",
    "        \n",
    "        # Level Final: ì „ì²´ í‰ê· /ìµœë¹ˆê°’\n",
    "        global_val = df_merged[col].mean() if df_target is df_sales else df_merged[col].mode()[0]\n",
    "        df_merged[col].fillna(global_val, inplace=True)\n",
    "        \n",
    "        # ì›ë³¸ ì—…ë°ì´íŠ¸\n",
    "        df_target[col] = df_merged[col]\n",
    "    \n",
    "    return df_target\n",
    "\n",
    "# --- 1. Sales ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ---\n",
    "# ë°°ë‹¬ë¹„ìœ¨, ì·¨ì†Œìœ¨ì€ ê°„ë‹¨í•˜ê²Œ ì²˜ë¦¬\n",
    "df_sales['ë°°ë‹¬ë§¤ì¶œê¸ˆì•¡ ë¹„ìœ¨'].fillna(0, inplace=True) # 2ì°¨: 0\n",
    "df_sales['ì·¨ì†Œìœ¨ êµ¬ê°„'].fillna(df_sales['ì·¨ì†Œìœ¨ êµ¬ê°„'].mean(), inplace=True) # 2ì°¨: ì „ì²´í‰ê· \n",
    "\n",
    "# 'í•´ì§€ ê°€ë§¹ì  ë¹„ì¤‘' ê³„ì¸µì  ëŒ€ì²´\n",
    "hierarchical_imputation(\n",
    "    df_sales, df_info, ['ë™ì¼ ìƒê¶Œ ë‚´ í•´ì§€ ê°€ë§¹ì  ë¹„ì¤‘'], \n",
    "    [['ê¸°ì¤€ë…„ì›”', 'ìƒê¶Œ'], ['ìƒê¶Œ'], ['ëŒ€ë¶„ë¥˜']]\n",
    ")\n",
    "\n",
    "# --- 2. Customer ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ---\n",
    "cust_cols = [c for c in df_customer.columns if 'ë¹„ì¤‘' in c or 'ë¹„ìœ¨' in c]\n",
    "hierarchical_imputation(\n",
    "    df_customer, df_info, cust_cols,\n",
    "    [['ê¸°ì¤€ë…„ì›”', 'ìƒê¶Œ', 'ì—…ì¢…'], ['ê¸°ì¤€ë…„ì›”', 'ìƒê¶Œ', 'ëŒ€ë¶„ë¥˜']]\n",
    ")\n",
    "\n",
    "print(\"===== ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì™„ë£Œ =====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1853799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== ì‹ì‚¬ ê·¸ë£¹ ì„¸ë¶„í™” ì™„ë£Œ =====\n",
      "ëŒ€ë¶„ë¥˜\n",
      "ì‹ì‚¬_ê·¸ë£¹_1    888\n",
      "ì‹ì‚¬_ê·¸ë£¹_0    813\n",
      "ì¹´í˜/ë””ì €íŠ¸     809\n",
      "ë¹„ì™¸ì‹ì†Œë§¤      657\n",
      "ê¸°íƒ€         401\n",
      "ì£¼ì /ìœ í¥      318\n",
      "ì‹ì‚¬_ê·¸ë£¹_2    290\n",
      "ì‹ì‚¬_ê·¸ë£¹_3      7\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1. êµ°ì§‘í™”ìš© ë°ì´í„° ì¤€ë¹„ (Info + Sales + Customer)\n",
    "df_merged_cluster = pd.merge(\n",
    "    df_sales[['ê°€ë§¹ì êµ¬ë¶„ë²ˆí˜¸', 'ê¸°ì¤€ë…„ì›”', 'ê°ë‹¨ê°€ êµ¬ê°„', 'ë°°ë‹¬ë§¤ì¶œê¸ˆì•¡ ë¹„ìœ¨']],\n",
    "    df_customer, on=['ê°€ë§¹ì êµ¬ë¶„ë²ˆí˜¸', 'ê¸°ì¤€ë…„ì›”'], how='inner'\n",
    ")\n",
    "df_final_cluster = pd.merge(df_info[['ê°€ë§¹ì êµ¬ë¶„ë²ˆí˜¸', 'ëŒ€ë¶„ë¥˜', 'ì—…ì¢…']], df_merged_cluster, on='ê°€ë§¹ì êµ¬ë¶„ë²ˆí˜¸', how='left')\n",
    "\n",
    "# 2. ì—…ì¢…ë³„ í”„ë¡œí•„ ìƒì„± (í‰ê· )\n",
    "features = ['ê°ë‹¨ê°€ êµ¬ê°„'] # í˜•ì´ ì„ íƒí•œ í”¼ì²˜ (í•„ìš”ì‹œ ì¶”ê°€)\n",
    "df_siksa = df_final_cluster[df_final_cluster['ëŒ€ë¶„ë¥˜'] == 'ì‹ì‚¬']\n",
    "df_industry_profiles = df_siksa.groupby('ì—…ì¢…')[features].mean()\n",
    "\n",
    "# 3. K-Means Clustering\n",
    "# ë°ì´í„° ì •ê·œí™”\n",
    "scaler = StandardScaler()\n",
    "scaled_profiles = scaler.fit_transform(df_industry_profiles)\n",
    "\n",
    "# ìµœì  êµ°ì§‘ ìˆ˜ (K=4) ì„¤ì • ë° í•™ìŠµ\n",
    "k = 4\n",
    "kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "clusters = kmeans.fit_predict(scaled_profiles)\n",
    "\n",
    "# 4. ê²°ê³¼ ë§¤í•‘ ('ì‹ì‚¬_ê·¸ë£¹_0', 'ì‹ì‚¬_ê·¸ë£¹_1'...)\n",
    "industry_to_cluster = pd.Series(clusters, index=df_industry_profiles.index)\n",
    "new_labels = df_info.loc[df_info['ëŒ€ë¶„ë¥˜'] == 'ì‹ì‚¬', 'ì—…ì¢…'].map(industry_to_cluster)\n",
    "df_info.loc[df_info['ëŒ€ë¶„ë¥˜'] == 'ì‹ì‚¬', 'ëŒ€ë¶„ë¥˜'] = 'ì‹ì‚¬_ê·¸ë£¹_' + new_labels.dropna().astype(int).astype(str)\n",
    "\n",
    "print(\"===== ì‹ì‚¬ ê·¸ë£¹ ì„¸ë¶„í™” ì™„ë£Œ =====\")\n",
    "print(df_info['ëŒ€ë¶„ë¥˜'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de9c7a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•„í„°ë§ ì „: 4183ê°œ\n",
      "í•„í„°ë§ í›„: 3623ê°œ (12ê°œì›” ì´ìƒ ìš´ì˜)\n"
     ]
    }
   ],
   "source": [
    "# 1. 12ê°œì›” ì´ìƒ ë°ì´í„°ê°€ ìˆëŠ” ê°€ê²Œ ì‹ë³„\n",
    "store_counts = df_sales['ê°€ë§¹ì êµ¬ë¶„ë²ˆí˜¸'].value_counts()\n",
    "valid_stores = store_counts[store_counts >= 12].index\n",
    "\n",
    "# 2. í•„í„°ë§ ì ìš© (VIP ë¦¬ìŠ¤íŠ¸ë§Œ ë‚¨ê¸°ê¸°)\n",
    "print(f\"í•„í„°ë§ ì „: {len(df_info)}ê°œ\")\n",
    "df_info = df_info[df_info['ê°€ë§¹ì êµ¬ë¶„ë²ˆí˜¸'].isin(valid_stores)].copy()\n",
    "df_sales = df_sales[df_sales['ê°€ë§¹ì êµ¬ë¶„ë²ˆí˜¸'].isin(valid_stores)].copy()\n",
    "df_customer = df_customer[df_customer['ê°€ë§¹ì êµ¬ë¶„ë²ˆí˜¸'].isin(valid_stores)].copy()\n",
    "print(f\"í•„í„°ë§ í›„: {len(df_info)}ê°œ (12ê°œì›” ì´ìƒ ìš´ì˜)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f18e05dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== ìš´ì˜ ê¸°ê°„ í”¼ì²˜ ìƒì„± ì™„ë£Œ =====\n",
      "   ê°€ë§¹ì ëª…    ì˜ì—…ê¸°ê°„_êµ¬ê°„\n",
      "0  ì„±ìš°**  4. ì¥ê¸°/ì‡ í‡´ê¸°\n",
      "1  ëŒ€ë³´**  4. ì¥ê¸°/ì‡ í‡´ê¸°\n",
      "2  ëŒ€ìš©**  4. ì¥ê¸°/ì‡ í‡´ê¸°\n",
      "3  í†µì¼**  4. ì¥ê¸°/ì‡ í‡´ê¸°\n",
      "4  í•œìš¸**  4. ì¥ê¸°/ì‡ í‡´ê¸°\n"
     ]
    }
   ],
   "source": [
    "# ê¸°ì¤€ì¼ ì„¤ì •\n",
    "ref_date = pd.to_datetime('2025-08-01')\n",
    "\n",
    "# ìš´ì˜ ê°œì›” ìˆ˜ ê³„ì‚°\n",
    "df_info['25ë…„ê¸°ì¤€_ìš´ì˜ê°œì›”ìˆ˜'] = (ref_date.year - df_info['ê°œì„¤ì¼'].dt.year) * 12 + \\\n",
    "                            (ref_date.month - df_info['ê°œì„¤ì¼'].dt.month)\n",
    "\n",
    "# êµ¬ê°„í™” (Binning)\n",
    "bins = [-1, 24, 48, 100, float('inf')]\n",
    "labels = ['1. ì´ˆê¸°', '2. ì„±ì¥ê¸°(ì£½ìŒì˜ê³„ê³¡)', '3. ì„±ìˆ™ê¸°', '4. ì¥ê¸°/ì‡ í‡´ê¸°']\n",
    "df_info['ì˜ì—…ê¸°ê°„_êµ¬ê°„'] = pd.cut(df_info['25ë…„ê¸°ì¤€_ìš´ì˜ê°œì›”ìˆ˜'], bins=bins, labels=labels)\n",
    "\n",
    "print(\"===== ìš´ì˜ ê¸°ê°„ í”¼ì²˜ ìƒì„± ì™„ë£Œ =====\")\n",
    "print(df_info[['ê°€ë§¹ì ëª…', 'ì˜ì—…ê¸°ê°„_êµ¬ê°„']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b99fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== ë§¤ì¶œ íŠ¸ë Œë“œ ë¶„ì„ ì™„ë£Œ =====\n",
      "ìµœì¢… í”¼ì²˜ ìˆ˜: 19ê°œ\n"
     ]
    }
   ],
   "source": [
    "# 1. ì›”ë³„ -> ë¶„ê¸°ë³„ Pivot\n",
    "df_sales['ê¸°ì¤€ë…„ì›”'] = pd.to_datetime(df_sales['ê¸°ì¤€ë…„ì›”'], errors='coerce')\n",
    "df_sales['ì—°ë„'] = df_sales['ê¸°ì¤€ë…„ì›”'].dt.year\n",
    "df_sales['ë¶„ê¸°'] = df_sales['ê¸°ì¤€ë…„ì›”'].dt.quarter\n",
    "quarterly_sales = df_sales.groupby(['ê°€ë§¹ì êµ¬ë¶„ë²ˆí˜¸', 'ì—°ë„', 'ë¶„ê¸°'])['ë§¤ì¶œê¸ˆì•¡ êµ¬ê°„'].mean().unstack(['ì—°ë„', 'ë¶„ê¸°'])\n",
    "quarterly_sales.columns = [f\"ë§¤ì¶œê¸ˆì•¡_{c[0]}ë…„_{c[1]}ë¶„ê¸°\" for c in quarterly_sales.columns]\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ ë³´ê°„ (ì•ë’¤ë¡œ ì±„ìš°ê¸°)\n",
    "quarterly_sales.fillna(method='ffill', axis=1, inplace=True)\n",
    "quarterly_sales.fillna(method='bfill', axis=1, inplace=True)\n",
    "\n",
    "# 2. í•„ì‚´ê¸° ì§€í‘œ ìƒì„± (ëª¨ë©˜í…€, ì•ˆì •ì„±, ìœ„í—˜ê°€ì†ë„)\n",
    "cols_23 = [c for c in quarterly_sales.columns if '23ë…„' in c]\n",
    "cols_24 = [c for c in quarterly_sales.columns if '24ë…„' in c]\n",
    "\n",
    "# ì„±ì¥ ëª¨ë©˜í…€ (24ë…„ í‰ê·  - 23ë…„ í‰ê· )\n",
    "quarterly_sales['ì„±ì¥_ëª¨ë©˜í…€'] = quarterly_sales[cols_24].mean(axis=1) - quarterly_sales[cols_23].mean(axis=1)\n",
    "\n",
    "# ì•ˆì •ì„± ì§€ìˆ˜ (ì „ì²´ ê¸°ê°„ í‘œì¤€í¸ì°¨)\n",
    "quarterly_sales['ì•ˆì •ì„±_ì§€ìˆ˜'] = quarterly_sales.std(axis=1)\n",
    "\n",
    "# ìœ„í—˜ ê°€ì†ë„ (24ë…„ í•˜ë°˜ê¸° - 24ë…„ ìƒë°˜ê¸°)\n",
    "cols_24_h1 = [c for c in cols_24 if '1ë¶„ê¸°' in c or '2ë¶„ê¸°' in c]\n",
    "cols_24_h2 = [c for c in cols_24 if '3ë¶„ê¸°' in c or '4ë¶„ê¸°' in c]\n",
    "quarterly_sales['ìœ„í—˜_ê°€ì†ë„'] = quarterly_sales[cols_24_h2].mean(axis=1) - quarterly_sales[cols_24_h1].mean(axis=1)\n",
    "\n",
    "# 3. ê²½ìŸë ¥ ì§€í‘œ (ë™ì¼ ì—…ì¢… ëŒ€ë¹„ ìˆœìœ„ ë“±) ë³€í™”ìœ¨\n",
    "comp_features = ['ë™ì¼ ì—…ì¢… ë§¤ì¶œê¸ˆì•¡ ë¹„ìœ¨', 'ë™ì¼ ì—…ì¢… ë‚´ ë§¤ì¶œ ìˆœìœ„ ë¹„ìœ¨', 'ìœ ë‹ˆí¬ ê³ ê° ìˆ˜ êµ¬ê°„', 'ê°ë‹¨ê°€ êµ¬ê°„']\n",
    "yearly_comp = df_sales.groupby(['ê°€ë§¹ì êµ¬ë¶„ë²ˆí˜¸', 'ì—°ë„'])[comp_features].mean().unstack('ì—°ë„')\n",
    "\n",
    "comp_report = pd.DataFrame(index=yearly_comp.index)\n",
    "for col in comp_features:\n",
    "    # 24ë…„ ê°’ê³¼ 23->24 ë³€í™”ìœ¨ ê³„ì‚°\n",
    "    comp_report[f'24ë…„_í‰ê· _{col}'] = yearly_comp[(col, 2024)]\n",
    "    comp_report[f'23_24_{col}_ë³€í™”'] = yearly_comp[(col, 2024)] - yearly_comp[(col, 2023)]\n",
    "\n",
    "# ìµœì¢… ë³‘í•©\n",
    "df_sales_final = pd.merge(quarterly_sales, comp_report, left_index=True, right_index=True, how='left')\n",
    "\n",
    "print(\"===== ë§¤ì¶œ íŠ¸ë Œë“œ ë¶„ì„ ì™„ë£Œ =====\")\n",
    "print(f\"ìµœì¢… í”¼ì²˜ ìˆ˜: {df_sales_final.shape[1]}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd18c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ! íŒŒì¼ ìƒì„±ë¨: df_info99.csv, df_sales99.csv, df_customer99.csv\n"
     ]
    }
   ],
   "source": [
    "# ì¸ë±ìŠ¤ ë¦¬ì…‹ í›„ ì €ì¥\n",
    "df_sales_final.reset_index(inplace=True)\n",
    "\n",
    "# ì €ì¥\n",
    "df_info.to_csv('./data/df_info99.csv', encoding='utf-8-sig', index=False)\n",
    "df_sales_final.to_csv('./data/df_sales99.csv', encoding='utf-8-sig', index=False)\n",
    "df_customer.to_csv('./data/df_customer99.csv', encoding='utf-8-sig', index=False)\n",
    "\n",
    "print(\"ëª¨ë“  ì‘ì—… ì™„ë£Œ! íŒŒì¼ ìƒì„±ë¨: df_info99.csv, df_sales99.csv, df_customer99.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
